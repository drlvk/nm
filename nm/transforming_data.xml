<?xml version="1.0" encoding="UTF-8" ?>

<chapter xml:id="chapter-transforming-data" xmlns:xi="http://www.w3.org/2001/XInclude">

<title>Transforming Data for LLS</title>


    <introduction>
        <p>The method of previous chapter works only for models in which parameters appear in a linear way, as coefficients to predetermined functions. This is often insufficient: for example, exponential and logistic models contain some parameters nonlinearly. In this chapter we expand the reach of Linear Least Squares method by transforming the variables involved in the problem, or by applying the method to the coefficients of an implicit function. 
      </p>
    </introduction>


<section xml:id="section-example-exponential-fit">
<title>Exponential fit</title>

<p>Exponential growth is modeled by a function of the form <m>f(x) = ae^{bt}</m>. Suppose we have some data 
<m>(x_k, y_k)</m>, <m>k=1, \dots, n</m>, and think that it describes exponential growth (which naturally occurs in ecology and epidemiology). A direct attempt to minimize the sum of differences squared: 
<men xml:id="eq-sum-squares-exponential">
  \sum_{k=1}^n \left(y_k - ae^{bx_k}\right)^2 \to \min 
</men>
is possible but requires optimization methods which we will consider later. There is an alternative approach:  instead of fitting <m>ae^{bx}</m> to the values <m>y_k</m>, fit its logarithm, <m>bx + \log a</m>, to the values 
<m>\log y_k</m>. This means we will minimize the sum of squares of differences of (natural) logarithms: 
<men xml:id="eq-sum-squares-exponential-log">
  \sum_{k=1}^n \left(\log(y_k) - bx_k - \log a\right)^2 \to \min
</men>
</p>

<p>It is important to understand the two problems <xref ref="eq-sum-squares-exponential" /> and <xref ref="eq-sum-squares-exponential-log" /> are not equivalent. If exact fit is possible, either approach will find it. But in general, some deviations (nonzero residuals) are inevitable, and the two approaches penalize deviations in different ways.</p>

<p>For example, if the given y-values are <c>[1 2 10]</c> and we have two competing exponential functions: one predicts <c>[0.5 2 10]</c> while the other predicts <c>[1 2 11]</c>. Using the penalty function <xref ref="eq-sum-squares-exponential" />, the first model has the penalty <m>0.25</m> while the second has penalty <m>1</m>, so the first looks better. But if we look at the differences of logarithms, then the first has penality 
<m>(\log 1 - \log 0.5)^2 = 0.48</m> while the second has penalty <m>(\log 10 - \log 11)^2 = 0.01</m>, so the second looks much better. </p>

<p>Most importantly, the minimization problem <xref ref="eq-sum-squares-exponential-log" /> can be easily solved using the method of <xref ref="chapter-linear-least-squares" />. For notational convenience let <m>\beta_1= \log a</m> and <m>\beta_2 = b</m>. If the left hand side of <xref ref="eq-sum-squares-exponential-log" /> was zero, that would mean that <m>\beta_1, \beta_2</m> is a solution of the overdetermined linear system
<men xml:id="eq-transformed-lls">  
\beta_1 + \beta_2  x_k = \log y_k,\quad k=1, \dots, n
</men>
The least squares solution of <xref ref="eq-transformed-lls" /> is the vector <m>\beta = (\beta_1, \beta_2)</m> that minimizes <xref ref="eq-sum-squares-exponential-log" />.   </p>  


<example xml:id="example-best-fit-exponential">
  <title>Fit an exponential to Covid data</title> 
<statement><p>The following are new Covid infections in France as reported on Fridays in September-October (from Sep 4 to Oct 23).
<cd>
y = [6011 7742 9335 12048 10946 14618 20399 29472]';  
</cd>
Fit an exponential function to this data, using week numbers <c>1:8</c> as x-values.
Extend it two weeks into the future by plotting it up to <m>x=10</m>. Include the original data on the plot.
</p> 
</statement>
<solution><p>The vector <c>y</c> is already defined above, but we need <c>yt = log(y)</c> to get transformed y-values.</p>
<pre> 
x = (1:8)';  
yt = log(y);
X = x.^(0:1); 
beta = X\yt;
f = @(x) exp((x.^(0:1))*beta);

t = linspace(1, 10, 1000)';
plot(t, f(t), 'b', x, y, 'r*')
</pre></solution></example>
</section>

<section xml:id="section-example-logistic-fit">
<title>Logistic fit</title>

<p>If we simplify the SIR model (<xref ref="section-ode-epidemiology" />) by removing the recovering process, the proportion of infected people in the population grows according to the ODE <m>y' = c y(1-y)</m> with some coefficient <m>c</m>. This ODE has an explicit solution 
<men xml:id="eq-logistic-function">
y = \frac{1}{1 + a e^{-kt}}
</men>
with <m>a, k > 0</m> depending on coefficient <m>c</m> (which we usually don't know in practice) and the initial condition <m>y(0)</m> (which we might not know either). But if we can collect some data, we can fit a logistic function <xref ref="eq-logistic-function" /> to it. As written, the model includes parameters <m>a, k</m> in a nonlinear way. But applying the <q>logit</q> transformation <m>\log(y/(1-y))</m> we obtain 
<men xml:id="eq-logistic-function-logit">
\log \frac{y}{1-y} = kt - \log a
</men>
Thus, we can fit a linear function to the values <m>\log(y_k/(1-y_k))</m> and then apply the inverse of the transformation <m>z = \log(y/(1-y))</m>, which is <m>y = 1 / (1+e^{-z})</m>. </p>

<p>The logistic model can reasonable apply to other processes which are slow initially, speed up, and then slow down again. The following example, where <q>population</q> consists of Covid-positive students, models the process of their recovery. </p>  

<example xml:id="example-best-fit-logistic">
  <title>Fit a logistic function to Covid data</title> 
<statement><p>There were at least 121 reported Covid infections among SU students between October 8 and October 26. The following are the cumulative counts of people recovered, day by day, starting with October 9.
<cd>
R = [1 1 1 5 8 10 27 44 62 93 101 110 112 115 116 117 118 120]';  
</cd>
Fit a logistic function to these <em>proportion</em> of the total <q>population</q> of 121 that recovered on each day. </p> 
</statement>
<solution><p>We need to compute proportions <c>y = R/121</c> and transform them by <c>yt = log(y./(1-y))</c>. Then the usual linear regression is applied. </p>
<pre> 
x = (1:numel(R))';  
y = R/121;
yt = log(y./(1-y));
X = x.^(0:1); 
beta = X\yt;
f = @(x) 1 ./ (1 + exp(-(x.^(0:1))*beta));

t = linspace(min(x), max(x), 1000)';
plot(t, f(t), 'b', x, y, 'r*')
</pre>
<p>Here the logistic function is written as <m>1/(1+\exp(-\beta_1 - \beta_2 x))</m> with parameters <m>\beta_1, \beta_2</m> contained in the vector <c>beta</c>.</p>
</solution></example>

<p> The result in <xref ref="example-best-fit-logistic" /> is not entirely satisfactory. The logit transformation over-emphasizes the values near 0 and 1, and de-emphasizes those in between. One way to address this issue is to introduce weights, which we do in next section.</p> 
</section> 


<section xml:id="section-weighted-least-squares">
<title>Weighted least squares</title>

<p>When we solve an overdetermined linear system <m>Az=b</m> as <c>z = A\b</c>, the result is the least squares solution which minimizes the sum <men xml:id="eq-penalty-lsq">\sum_k ((Az)_k-b_k)^2</men> (the penalty). For example, the difference of <m>0.1</m> between <m>(Az)_k</m> and <m>b_k</m> contributes <m>0.01</m> to the penalty, no matter what <m>k</m> is. 
But in some contexts we may want to treat different data points differently:
<ul>
  <li>We are more certain about some of the numbers <m>b_k</m> than others. </li>
  <li>Some of the numbers are much larger than others, and we expect the absolute errors for them to be larger.</li>
  <li>We applied some transformation to the data, like in the previous sections.</li>
</ul>
In such cases we may want to introduce <em>weights</em> <m>w_k</m> (some positive numbers) and minimize the sum 
<men xml:id="eq-penalty-lsq-weights">\sum_k ((Az)_k-b_k)^2 w_k^2</men> instead of <xref ref="eq-penalty-lsq" />. Larger weights mean that we penalize the residuals (the differences between the model and the data) more. 
To solve this <em>weighted least squares</em> problem in Matlab, we need to multiply the first equation in <m>Az=b</m>
by <m>w_1</m>, the second by <m>w_2</m>, and so on. To do this, arrange the weights into a column vector <c>w</c> and let <cd>z = (A.*w)\(b.*w)</cd>. The array operations <c>.*</c> take care of multiplying each equation by its weight.</p>

<p>Weights can be used to mitigate the distortion caused by data transformation of the form <m>\hat y = T(y)</m>. 
Indeed, the application of <m>T</m> magnifies the errors around <m>y=y_k</m> by the factor of <m>|T'(y_k)|</m>. If this is undesirable, we should use the weights <m>w_k = 1/|T'(y_k)|</m> to compensate. </p>

<p>In <xref ref="example-best-fit-logistic" /> we used the logit transformation <m>T(y) = \log(y/(1-y)) = \log(y) - \log(1-y)</m>. Its derivative is <me>T'(y) = \frac{1}{y} + \frac{1}{1-y} = \frac{1}{y(1-y)}</me>. This is a positive quantity, so we do not need absolute value; the weights are simply <m>w_k = y_k(1-y_k)</m>. </p>


<example xml:id="example-weighted-fit-logistic">
  <title>Use weighted least squares to fit a logistic function</title> 
<statement><p>Improve the solution of <xref ref="example-best-fit-logistic" /> by using weights to compensate for data transformation. Compare the results to the previous ones. </p></statement>
<solution><p>We continue the code from <xref ref="example-best-fit-logistic" /> by adding the following lines.</p>
<pre> 
w = y.*(1-y);            % weights 
beta = (X.*w)\(yt.*w);   % weighted least squares solution
f = @(x) 1 ./ (1 + exp(-(x.^(0:1))*beta));
figure();
plot(t, f(t), 'b', x, y, 'r*')
title('Weighted Least Squares')
</pre>
<p>The first two lines compute new parameters <m>\beta_1, \beta_2</m> for logistic function <m>1/(1+\exp(-\beta_1 - \beta_2 x))</m>, using weights. The rest proceeds as before. The plot is shown on a new figure. </p>
</solution></example>

<p>Note that we do not <em>always</em> want to compensate for data transformation by using weights <m>w_k = 1/|T'(y_k)|</m>. Linear regression works best if the standard deviation of different values <m>y_k</m> (assumed to include random errors) is about the same. When the values grow exponentially and are measured with the same relative accuracy, the standard deviation will grow with the values. In this case, the logarithmic transformation 
<m>T(y)=\log y</m> may help with non-linearity of the model <em>and</em> with the uniformity of standard deviations.
</p>
</section>



<section xml:id="section-example-implicit-equation">
<title>Fitting an implicit equation</title>

<p>This is an optional section, feel free to skip it.</p> 

<p>Not all data points represent a function of the form <m>y = f(x)</m>. They may happen to accumulate along some closed curve such as an ellipse. General implicit equation of an ellipse is 
<men xml:id="eq-ellipse-implicit">
Ax^2 + Bxy + Cy^2 + Dx + Ey  = 1
</men>
There are five unknown coefficients here. So, given a set of points <m>(x_k, y_k)</m>, <m>k=1, \dots, n</m>, we get a linear system by plugging each point into <xref ref="eq-ellipse-implicit" />. Its least squares solution describes an ellipse that fits the data best in the sense of having the smallest sum 
<me>\sum_{k=1}^n (Ax_k^2 + Bx_ky_k + Cy_k^2 + Dx_k + Ey_k  - 1)^2</me>
which should hopefully fit the ellipse. </p>


<example xml:id="example-best-fit-ellipse">
  <title>Fit an ellipse to given points</title> 
<statement><p>Plot an ellipse that fits the given 7 data points: 
<cd>  
x = [1 2 4 5 4 3 1]'; 
y = [2 0 -1 1 2 3 4]';
</cd>
Then plot it together with the points, using <c>fimplicit</c> command. Its syntax is 
<cd>
fimplicit(@(x, y) ..., [xmin xmax ymin ymax])  
</cd>
where the first argument is the implicit equation (something equated to 0), and the second is the plot window.</p>
</statement>
<solution>
<pre> 
X = [x.^2 x.*y y.^2 x y];
b = X\ones(7, 1);
hold on
plot(x, y, 'r*')
fun = @(x, y) b(1)*x.^2 + b(2)*x.*y + b(3)*y.^2 + b(4)*x + b(5)*y - 1;
win = [min(x)-1 max(x)+1 min(y)-1 max(y)+1]; 
fimplicit(fun, win)
hold off
</pre>
<p>Here the vector of parameters is called <c>b</c> instead of <c>beta</c> to shorten the implicit formula.
It is obtained by solving a system with 1 on the right hand side, according to <xref ref="eq-ellipse-implicit" />. The plot window is calculated from the data to allow margins of 1 unit on all sides.</p>

<p> Note that while it's safe to leave spaces around <c>+</c> signs in the formula <c>fun</c> (some find it improves readability), one has to be extra careful with such spaces within a vector. Indeed, 
<cd>
[min(x) -1 max(x) +1 min(y) -1 max(y) +1]  
</cd>
would be a vector of 8 numbers, not 4. Matlab does understand 
<cd>
[min(x) - 1 max(x) + 1 min(y) - 1 max(y) + 1];
</cd>
as a vector of 4 numbers, however. </p>
</solution></example>

<question><title>Vectorizing a function for implicit plot</title>
<p>It is tempting to write the anonymous function as <c>fun = @(x, y) [x.^2 x.*y y.^2 x y]*b - 1</c> which is shorter and consistent with how we used parameters in the past. And this works but Matlab complains: 
<q>Warning: Function behaves unexpectedly on array inputs. To improve performance, properly vectorize your function to return an output with the same size and shape as the input arguments.</q> What is it complaining about? </p>
</question>
</section>

<exercises xml:id="exercises-transforming-data">
    <title>Homework</title>

    <exercise number="1">
        <statement>
<p> A <term>power law</term> is a function of the form <m>y = a x^p</m>. By taking logarithm on both sides we get <m>\log y = p \log x + \log a</m>, which is a linear function of <m>\log x</m>. So, to fit a power law to given data <m>(x_k, y_k)</m>, we apply the logarithm to both <m>x_k</m> and <m>y_k</m>, and follow the linear regression process.  Try this with France Covid data <xref ref="example-best-fit-exponential" />. Does the power law fit better or worse than exponential? (Compare visually, on the basis of plots.) </p></statement> </exercise>
  
<exercise number="2" xml:id="exercise-transforming-data-2">
        <statement>
<p> The number of active Covid cases at SU during October 1 - October 23 is given below.
<cd>
y = [5 5 4 5 9 25 45 65 77 87 87 89 97 101 90 74 57 26 20 13 12 12 13]'; 
</cd>
The x-values can be <c>x = (1:23)'</c>. Try to fit a <q>bell-shaped</q> Gaussian function 
<m>y = \exp(Ax^2+Bx+C)</m> (where <m>A\lt 0</m>) to the data. This can be done by the logarithmic transformation 
<c>yt = log(y)</c> followed by fitting a quadratic function to <c>yt</c>. Fit a quadratic function by solving a system with the matrix <c>X = x.^(0:2)</c>, without weights. Having found the parameters <c>beta</c>, we get a suitable function <c>f = @(x) exp(x.^(0:2)*beta)</c> which should be plotted together with the data points. 
</p></statement></exercise>

<exercise number="3">
        <statement>
<p> Repeat <xref ref="exercise-transforming-data-2" />, using weights as explained in <xref ref="section-weighted-least-squares" />. Does the new curve fit better or worse than the curve in <xref ref="exercise-transforming-data-2" />? 
</p></statement></exercise>
 
</exercises>

</chapter>

  