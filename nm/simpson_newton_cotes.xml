<?xml version="1.0" encoding="UTF-8" ?>

<chapter xml:id="chapter-simpson-newton-cotes" xmlns:xi="http://www.w3.org/2001/XInclude">

<title>Simpson's rule and other Newton-Cotes rules</title>


    <introduction>
        <p>This chapter introduces more sophisticated integration rules which attach different weights to different points of evaluation. However, the evaluation points are still chosen in a simple way, by putting them at equal distance from one another. This will eventually become a problem.</p>
    </introduction>

<section xml:id="section-simpson-rule">
<title>Simpson's rule</title>

<p>Consider the trapezoidal rule on the interval <m>[-1,1]</m> with <m>n=2</m>. It has <m>h=1</m>, so 
<men xml:id="eq-trap1">
\int_{-1}^{1} f(x)\,dx \approx  f(0) +  \frac{1}{2}(f(-1)+f(1))
</men>
Surprisingly, the approximation <xref ref="eq-trap1" /> can be made much more precise without doing more computations. As in <xref ref="section-richardson-extrapolation" />, we use the Richardson extrapolation to improve the accuracy. The same trapezoidal rule with doubled step size <m>h=2</m> yields
<men xml:id="eq-trap2">
\int_{-1}^{1} f(x)\,dx \approx \frac{2}{2} (f(-1)+f(1)) 
</men>
Since the error of trapezoidal rule is proportional to <m>h^2</m> (the rule has second order of accuracy), we expect the second approximation <xref ref="eq-trap2" /> to have error 4 times greater than the first approximation <xref ref="eq-trap1" />. To cancel out most of the error, we divide <xref ref="eq-trap2" /> by 4 and subtract it from <xref ref="eq-trap1" />. The result is
<me>
\frac34 \int_{-1}^{1} f(x)\,dx \approx f(0) +  \frac{1}{2}(f(-1)+f(1)) - \frac14 (f(-1)+f(1)) 
</me>
Hence 
<men xml:id="eq-simps1">
\int_{-1}^{1} f(x)\,dx \approx \frac43 f(0) + \frac{1}{3}(f(-1)+f(1))
</men>
The approximation <xref ref="eq-simps1" /> uses the same information about function <m>f</m> as the 
trapezoidal rule <xref ref="eq-trap1" />: the values at -1, 0, 1. But the result is much more accurate. Consider, for example, the integral <m>\int_{-1}^1 e^x\,dx = e - 1/e \approx 2.3504</m>. The trapezoidal rule <xref ref="eq-trap1" /> approximates it by  
<me>
e^0 +  \frac{1}{2}(e^{-1} + e^1) \approx 2.5431     
</me>
with the error of 0.1927.  The formula <xref ref="eq-simps1" /> produces 
<me>
\frac43 e^0 + \frac{1}{3}(e^{-1}+ e^1) \approx 2.3621
</me>
with the error of 0.0117. This is 16 times more accurate. This improvement was achieved by changing the 
<term>weights</term> (coefficients) attached to the values <m>f(-1), f(0), f(1)</m>: for trapezoidal rule they are <m>1/2, 1, 1/2</m>, but the formula <xref ref="eq-simps1" /> uses the weights <m>1/3, 4/3, 1/3</m>. 
The formula <xref ref="eq-simps1" /> is Simpson's rule (with <m>n=2</m> subintervals) on the interval <m>[-1, 1]</m>. On a general interval <m>[a, b]</m> it becomes, via a change of variable, 
<men xml:id="eq-simps1a">
\int_{a}^{b} f(x)\,dx \approx \frac{b-a}{6} (f(a) + 4f((a+b)/2) + f(b))
</men>
Check that <xref ref="eq-simps1a" /> is consistent with <xref ref="eq-simps1" />: the midpoint gets greater weight than the endpoints by the factor of 4, and the sum of weights is <m>b-a</m>. </p>
 
<p>Simpson's rule can be used with more subintervals, but their number <m>n</m> has to be even, since we are combining trapezoidal rule with <m>n</m> and <m>n/2</m> subintervals. With <m>h=(b-a)/n</m> we get 
<men xml:id="eq-simps2">
\int_a^b f(x)\,dx \approx \frac{h}{3}(1,4,2,4,\dots,2,4,1) \cdot (\text{vector of y-values})  
</men>
A better way to think of this formula is that we first divide the interval into some number of equal parts and then use Simpson's rule on each part. The result is called <q>composite Simpson's rule</q> in contrast to the <q>simple Simpson's rule</q> that we started with.
</p>

<p>To summarize: Simpson's rule is the result of Richardson extrapolation of the Trapezoidal rule.
Following the process in <xref ref="section-lrtm-error-estimates" /> one can find that its order of accuracy is 4, meaning the error is proportional to <m>h^4</m>.</p>
</section>

<section xml:id="section-simpson-other-derivation">

<title>Other derivations of Simpson's rule</title>  

<p>A simple way to arrive at Simpson's rule is to observe that Midpoint rule and Trapezoidal rule have errors of opposite signs due to concavity. This suggests averaging them to improve the accuracy. But the simple average <m>(M+T)/2</m> would not achieve much because the error of midpoint rule is about half of the error of trapezoidal rule, according to the estimates in <xref ref="chapter-trapezoid-midpoint" />. Instead, the weighted average <m>(2M+T)/3</m> is used, giving weight <m>2/3</m> to Midpoint and <m>1/3</m> to Trapezoidal. The result is Simpson's rule. </p>
	
<p>But historically Simpson's rule was derived from <em>parabolic interpolation</em>, following the same line of reasoning that produces Trapezoid rule from <em>linear interpolation</em>. For simplicity, consider a function <m>f</m> on the interval <m>[-1, 1]</m>. We are looking for a parabola <m>g(x) = Ax^2+Bx+C</m> that agrees with <m>f</m> at three points <m>-1, 0, 1</m>. This can be done by observing that 
<ul>
	<li> <m>C=g(0)=f(0)</m></li>
	<li> <m>2B=g(1)-g(-1)=f(1)-f(-1)</m></li>
	<li> <m>2A = g(1)+g(-1)-2g(0) = f(1)+f(-1)-2f(0)</m></li>
</ul>
We arrive at 
<me>
\int_{-1}^1 f(x)\,dx \approx \int_{-1}^1 g(x)\,dx = \frac{2}{3}A + 2C = \frac{f(1)+ 4f(0) + f(-1)}{3}
</me>
which is Simpson's rule. </p>
</section>

 
<section xml:id="section-newton-cotes">
<title>Newton-Cotes rules</title>

<p>One can create rules of any given order of accuracy, using enough sample points. Usually such rules are derived for the convenient interval <m>[-1,1]</m>, and then applied to other intervals by change of variable.</p>

<p>Let <m>(x_1,\dots, x_n)</m> be some points in the interval <m>[-1,1]</m>. We want to come up with an integration rule
<men xml:id="eq-cotes1">
\int_{-1}^1 f(x)\,dx \approx w_1 f(x_1) + \dots + w_n f(x_n)
</men>
where <m>w_k</m> are coefficients (weights). For example, Simpson's rule (in its simple form) has evaluation points <m>-1,0,1</m> and weights <m>1/3, 4/3, 1/3</m>.</p>

<p>How to find the weights that make the rule <xref ref="eq-cotes1" /> as accurate as possible? We can require both sides to be equal when <m>f</m> is each of the following: <m>x^0, x^1, \dots, x^{n-1}</m>. This gives <m>n</m> linear equations with <m>n</m> unknowns <m>w_j</m>. Then solve the system, perhaps using Matlab. 
The resulting rules are called Newton-Cotes rules when the points are distributed at equal intervals. They include trapezoidal rule (2 points) and Simpson's rule (3 points) as special cases. 
</p>

<example xml:id="example-find-cotes-weights">
  <title>Find the weights for a 5-point Newton-Cotes formula </title>
<statement><p>Let evaluation points on <m>[-1, 1]</m> be <m>-1, -1/2, 0, 1/2, 1</m>. What will their weights be?</p> </statement>

<solution><p> We need 5 linear equations involving integrals of <m>x^0, x^1, \dots, x^4</m>. If we number them by index <m>i</m> running from 1 to 5, then the equation has <m>\int_{-1}^1 x^{i-1}\,dx</m>  on the right hand side, which is <m>(1-(-1)^i)/i</m>. On the left we have the sum <m>\sum_j w_j x_j^{i-1}</m> which means the coefficients of the unknown <m>w_j</m> is <m>x_j^{i-1}</m>. We can create a matrix using outer exponentiation of a row vector by a column vector.</p> 
<pre>
n = 5;
x = linspace(-1, 1, n);
i = (1:n)'; 
A = x.^(i-1);
b = (1-(-1).^i)./i;
w = A\b;
disp(rats(w'))
</pre>
<p>Here <c>rats</c> is used to display the solution as rational numbers (which they are) rather than the usual decimal approximation.</p>

<p>Having computed the weights as above, we can integrate any function f on [-1, 1] simply by executing
<c>f(x)*w</c>, which is the dot product of a vector with function values with the vector of weights. Try this for the exponential function.</p></solution>  
</example>

<p>Although one can get rules of arbitrarily high order in this way, the gain in practice does not justify the increasing complexity. (Try computing the 9-point rule, for example). It turns out that using many equally spaced points on an interval is generally a bad idea. We need a smarter way of choosing the points, which we will start working on next time.</p> 
</section>
 
<section xml:id="examples-simpson-newton-cotes">

<title>Examples and questions</title>  

<example xml:id="example-simpson-rule-compare"><title>Comparing the accuracy of Simpson's, trapezoidal, and midpoint rules</title>
<statement><p>For the function <m>f(x) = e^x </m> on the interval <m>[0, 1]</m>, use Matlab to compute 
the left-, right, and midpoint approximations with <m>n=10</m> and find the error of each approximation (that is, its difference with the actual integral). </p>

<p>Then repeat the same with <m>f(x) = e^{\sqrt{x}} </m>. What could explain the lackluster performance of Simpson's rule here? </p>

</statement>
<solution><pre>
f = @(x) exp(x);  % or exp(sqrt(x))
a = 0;
b = 1;
exact = exp(1)-1;  % or 2

n = 10;
h = (b-a)/n;
x = a:h:b;
y = f(x);   

T = (h/2)*(y(1) + y(end) + 2*sum(y(2:end-1))); 
S = (h/3)*(y(1) + y(end) + 4*sum(y(2:2:end-1)) + 2*sum(y(3:2:end-2))); 
midpoints = (x(1:end-1) + x(2:end))/2;
M = h*sum(f(midpoints));

er = abs([T M S] - exact);
fprintf('Errors: Trapezoidal %g, Midpoint %g, Simpson %g\n', er);
</pre>
<p>The function <m>f(x) = e^{\sqrt{x}} </m> is not differentiable at <m>0</m>. This behavior affects higher order methods more because they are based on comparing the function to a smooth one (such as a parabola). The midpoint method has an advantage in that it does not use the problematic point <m>0</m>.</p>
</solution></example>


<question><title>Richardson extrapolation of the midpoint rule</title>
<p>We derived Simpson's rule from trapezoidal rule using the Richardson extrapolation. Why not do the same 
	starting from the midpoint rule instead of trapezoidal? 
</p>
</question> 
 
</section>


<exercises xml:id="exercises-simpson-newton-cotes">
    <title>Homework</title>

    <exercise number="1">
        <statement>
<p> Sometimes one needs an <q>open-ended</q> version of Newton-Cotes rules, which does not use the values of the function at the endpoints (because the function may not be defined at the endpoints). Find the coefficients in the integration rule  
<me>
\int_{-1}^1 f(x)\,dx \approx w_1 f(-1/2) + w_2 f(0) + w_3 f(1/2)
</me>
so that the rule is precise for <m>x^0</m>, <m>x^1</m>, and <m>x^2</m>. (You can use Matlab for solving the system of equations for the weights.)  
</p>
</statement></exercise>


<exercise number="2">
        <statement>
<p> Apply the integration rule derived in the previous exercise to <m>\int_{-1}^1 (1-x^2)^{-1/4}\,dx</m>. 
How close is the result to the actual value of the integral (you can find it, for example, with WolframAlpha)? 
</p>
</statement></exercise>

<exercise number="3">
        <statement>
<p> In a loop over <c>n=2:10</c>, do the following. First, compute the weights for <m>n</m>-point Newton-Cotes rule (of the standard type, as in <xref ref="example-find-cotes-weights" />). Then use this rule to approximate <m>\int_{-1}^1 e^x\,dx</m>. After the loop ends you should have 9 approximations to this integral. Show how their accuracy changes with <m>n</m> by plotting the absolute value of the difference between the integral and approximation, as a function of <m>n</m>. Use <c>semilogy</c> instead of <c>plot</c> to show the plot on logarithmic scale. </p>
</statement></exercise>



</exercises> 

</chapter>

